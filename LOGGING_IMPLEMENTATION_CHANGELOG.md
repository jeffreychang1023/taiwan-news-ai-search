# Logging Infrastructure Implementation - Change Log

**Date:** 2025-01-XX
**Purpose:** Add comprehensive analytics/logging system for ML training data collection
**Status:** In Progress

---

## Summary

Implementing Track A of the search enhancement plan: Adding logging infrastructure to collect training data for XGBoost ranking model.

---

## New Files Created

### 1. Backend - Core Logging Module
**File:** `code/python/core/query_logger.py`
**Lines:** 680 lines
**Purpose:** Async query logging system with SQLite database
**Dependencies:**
- sqlite3
- asyncio
- threading
- misc.logger.logging_config_helper

**Database Schema Created:**
- `queries` table - Query metadata, timing, costs
- `retrieved_documents` table - Retrieved items before ranking
- `ranking_scores` table - LLM/XGBoost ranking scores
- `user_interactions` table - Clicks, dwell time, scroll depth
- `feature_vectors` table - ML features for training

**Key Functions:**
- `log_query_start()` - Start tracking a query
- `log_query_complete()` - Complete query with metrics
- `log_retrieved_document()` - Log retrieval results
- `log_ranking_score()` - Log ranking scores
- `log_user_interaction()` - Log clicks/dwell time
- `log_feature_vector()` - Log ML features
- `get_query_stats()` - Get analytics statistics

**Database Location:** `data/analytics/query_logs.db`

---

### 2. Frontend - Analytics Tracker Module
**File:** `static/analytics-tracker.js`
**Lines:** 364 lines
**Purpose:** Client-side event tracking (clicks, dwell time, scroll depth)
**Dependencies:** None (vanilla JS)

**Key Classes:**
- `AnalyticsTracker` - Main tracker class
- Methods:
  - `startQuery()` - Start tracking new query
  - `trackResultDisplayed()` - Track result shown
  - `trackClick()` - Track click on result
  - `trackDwellTime()` - Track time spent
  - `trackScrollDepth()` - Track scroll percentage
  - `sendEvent()` - Send to backend via WebSocket

**Features:**
- Intersection Observer for visibility tracking
- Page Visibility API for accurate dwell time
- Scroll depth measurement
- WebSocket event transmission
- Privacy-conscious (no PII collection)

---

### 3. Analytics Dashboard
**File:** `static/analytics-dashboard.html`
**Lines:** 510 lines
**Purpose:** Web-based analytics dashboard for viewing stats
**Dependencies:** None (standalone HTML/CSS/JS)

**Features:**
- Real-time statistics cards
- Recent queries table
- Top clicked results table
- CSV export for training data
- Auto-refresh every 30s
- Time range selector (1d, 7d, 30d, 90d, 365d)

**API Endpoints Used:**
- `GET /api/analytics/stats`
- `GET /api/analytics/queries`
- `GET /api/analytics/top_clicks`
- `GET /api/analytics/export_training_data`

---

### 4. Backend - Analytics API Handler
**File:** `code/python/webserver/analytics_handler.py`
**Lines:** 507 lines (updated)
**Purpose:** REST API endpoints for analytics dashboard + event handling
**Dependencies:**
- aiohttp
- sqlite3
- hashlib (for IP hashing)
- misc.logger.logging_config_helper

**Key Functions:**
- `get_stats()` - Return overall statistics
- `get_queries()` - Return recent queries with CTR
- `get_top_clicks()` - Return most clicked results
- `export_training_data()` - Export CSV for ML training
- **`handle_analytics_event()`** - Handle single event from frontend (NEW)
- **`handle_analytics_batch()`** - Handle batch of events from frontend (NEW)
- **`_hash_ip()`** - Hash client IP for privacy (NEW)
- `register_analytics_routes()` - Register routes with app (updated)

**Endpoints:**
- `GET /api/analytics/stats?days=7`
- `GET /api/analytics/queries?days=7&limit=50`
- `GET /api/analytics/top_clicks?days=7&limit=20`
- `GET /api/analytics/export_training_data?days=7`
- **`POST /api/analytics/event`** - Receive single analytics event (NEW)
- **`POST /api/analytics/event/batch`** - Receive batch of events (NEW)

---

### 5. Frontend - SSE-Compatible Analytics Tracker
**File:** `static/analytics-tracker-sse.js`
**Lines:** 485 lines
**Purpose:** Analytics tracker for SSE-based frontends (uses HTTP POST instead of WebSocket)
**Dependencies:** None (vanilla JS)

**Key Classes:**
- `AnalyticsTrackerSSE` - Main tracker class for SSE frontends

**Key Differences from WebSocket Version:**
- Uses HTTP POST (`fetch`) to send events
- Batches events every 5 seconds to reduce requests
- Sends clicks immediately for accuracy
- Compatible with news-search-prototype.html

**Methods:**
- `startQuery()` - Start tracking new query
- `trackResultDisplayed()` - Track result shown
- `trackClick()` - Track click (immediate send)
- `trackDwellTime()` - Track time spent
- `trackScrollDepth()` - Track scroll percentage
- `queueEvent()` - Queue event for batching
- `sendEventImmediate()` - Send event immediately via POST
- `flushEvents()` - Flush batch via POST

---

### 6. Integration Documentation
**File:** `ANALYTICS_INTEGRATION_INSTRUCTIONS.md`
**Lines:** 350+ lines
**Purpose:** Step-by-step guide for integrating analytics into news-search-prototype.html

**Contains:**
- Step-by-step integration instructions
- Code snippets for each modification point
- Alternative simpler approach using event delegation
- Testing procedures
- Troubleshooting guide
- Rollback instructions

---

### 7. Integration Snippet
**File:** `static/analytics-integration-snippet.html`
**Lines:** 110 lines
**Purpose:** Ready-to-use code snippet with inline comments for quick integration

---

## Modified Existing Files

### 1. Frontend - JSON Renderer
**File:** `static/json-renderer.js`
**Modified Lines:** 4-5, 12-24, 178-193

**Changes Made:**

#### Addition 1: Import analytics tracker (Line 4-5)
```javascript
// ADDED:
import { attachClickTracking, getAnalyticsTracker } from './analytics-tracker.js';

export class JsonRenderer {
```

**Rationale:** Enable analytics tracking on rendered results

---

#### Addition 2: Add result index tracker (Line 22-23)
```javascript
constructor(options = {}) {
  this.options = { ... };
  this.typeRenderers = {};

  // ADDED:
  // Track result index for analytics
  this.resultIndex = 0;
}
```

**Rationale:** Track position of each result for analytics

---

#### Addition 3: Attach analytics tracking to results (Line 178-193)
```javascript
// ORIGINAL (Line 176):
container.appendChild(contentDiv);

// Add image if available
this.addImageIfAvailable(item, container);

return container;

// MODIFIED TO:
container.appendChild(contentDiv);

// Add image if available
this.addImageIfAvailable(item, container);

// ADDED:
// Attach analytics tracking
const position = this.resultIndex++;
const url = item.url || '';
if (url) {
  // Attach click tracking to the container
  attachClickTracking(container, url, position);

  // Track that this result was displayed
  const tracker = getAnalyticsTracker();
  tracker.trackResultDisplayed(url, position, {
    title: item.name || item.title || '',
    site: item.site || item.source_site_name || '',
    has_image: !!item.image
  });
}

return container;
```

**Rationale:** Automatically track clicks and visibility for all rendered results

---

### 2. Frontend - Chat Interface (Unified)
**File:** `static/chat-interface-unified.js`
**Modified Lines:** 8, 394-396, 617-621

**Changes Made:**

#### Addition 1: Import analytics tracker (Line 8)
```javascript
// ORIGINAL:
import { ConversationManager } from './conversation-manager.js';
import { ManagedEventSource } from './managed-event-source.js';
import { ChatUICommon } from './chat-ui-common.js';

// MODIFIED TO:
import { ConversationManager } from './conversation-manager.js';
import { ManagedEventSource } from './managed-event-source.js';
import { ChatUICommon } from './chat-ui-common.js';
import { getAnalyticsTracker } from './analytics-tracker.js';  // ADDED
```

**Rationale:** Enable analytics tracking in chat interface

---

#### Addition 2: Initialize tracker on WebSocket connect (Line 394-396)
```javascript
// ORIGINAL (Line 390-403):
this.ws.connection.onopen = () => {
  this.ws.reconnectAttempts = 0;
  delete this.ws.connectingPromise;

  // Request sites when connection opens...
  // Send any queued messages
  this.flushMessageQueue();

  resolve();
};

// MODIFIED TO:
this.ws.connection.onopen = () => {
  this.ws.reconnectAttempts = 0;
  delete this.ws.connectingPromise;

  // ADDED:
  // Initialize analytics tracker with WebSocket connection
  const tracker = getAnalyticsTracker(this.ws.connection);
  console.log('[Analytics] Tracker initialized with WebSocket');

  // Request sites when connection opens...
  // Send any queued messages
  this.flushMessageQueue();

  resolve();
};
```

**Rationale:** Set WebSocket connection for sending analytics events

---

#### Addition 3: Track query on send (Line 617-621)
```javascript
// ORIGINAL (Line 614-624):
// Create the message with conversation context
const message = this.createUserMessage(messageText, conversation, searchAllUsers);

// Display and store locally
this.handleStreamData(message, true);

// MODIFIED TO:
// Create the message with conversation context
const message = this.createUserMessage(messageText, conversation, searchAllUsers);

// ADDED:
// Start analytics tracking for this query
const tracker = getAnalyticsTracker();
const queryId = message.message_id || `query_${Date.now()}`;
tracker.startQuery(queryId, messageText);
console.log('[Analytics] Started tracking query:', queryId);

// Display and store locally
this.handleStreamData(message, true);
```

**Rationale:** Start tracking each query when user sends it

---

### 3. Backend - Analytics API Handler
**File:** `code/python/webserver/analytics_handler.py`
**Modified Lines:** 341-507 (added new methods and routes)

**Changes Made:**

#### Addition 1: handle_analytics_event method (Lines 341-403)
```python
# ADDED:
async def handle_analytics_event(self, request: web.Request) -> web.Response:
    """Handle single analytics event from frontend."""
    # ... (receives POST with event data, logs to database)
```

**Rationale:** Handle individual analytics events from SSE frontend via HTTP POST

---

#### Addition 2: handle_analytics_batch method (Lines 405-457)
```python
# ADDED:
async def handle_analytics_batch(self, request: web.Request) -> web.Response:
    """Handle batch of analytics events from frontend."""
    # ... (receives batch of events, processes each)
```

**Rationale:** Handle batched events to reduce HTTP request overhead

---

#### Addition 3: _hash_ip method (Lines 459-484)
```python
# ADDED:
def _hash_ip(self, request: web.Request) -> str:
    """Hash client IP address for privacy."""
    # ... (extracts IP from headers, hashes with salt)
```

**Rationale:** Privacy-conscious IP hashing for analytics

---

#### Modification 4: register_analytics_routes (Lines 503-506)
```python
# ORIGINAL:
app.router.add_get('/api/analytics/stats', handler.get_stats)
app.router.add_get('/api/analytics/queries', handler.get_queries)
app.router.add_get('/api/analytics/top_clicks', handler.get_top_clicks)
app.router.add_get('/api/analytics/export_training_data', handler.export_training_data)

# MODIFIED TO (ADDED):
# Analytics data endpoints
app.router.add_get('/api/analytics/stats', handler.get_stats)
app.router.add_get('/api/analytics/queries', handler.get_queries)
app.router.add_get('/api/analytics/top_clicks', handler.get_top_clicks)
app.router.add_get('/api/analytics/export_training_data', handler.export_training_data)

# Analytics event endpoints (for frontend tracking)
app.router.add_post('/api/analytics/event', handler.handle_analytics_event)
app.router.add_post('/api/analytics/event/batch', handler.handle_analytics_batch)
```

**Rationale:** Register POST endpoints for receiving analytics events from frontend

---

### 4. Frontend - News Search Prototype
**File:** `static/news-search-prototype.html`
**Modified Lines:** 1145-1147, 1199-1248, 1705-1708, 1833-1835

**Changes Made:**

#### Addition 1: Add analytics tracker script (Lines 1145-1147)
```html
<!-- ADDED: -->
<!-- Analytics Tracker -->
<script src="/analytics-tracker-sse.js"></script>

<script>
    const searchInput = document.getElementById('searchInput');
```

**Rationale:** Load the SSE-compatible analytics tracker

---

#### Addition 2: Initialize analytics tracker (Lines 1199-1248)
```javascript
// Mode tracking: 'search' or 'chat'
let currentMode = 'search';

// ADDED:
// ==================== ANALYTICS INITIALIZATION ====================
const analyticsTracker = new AnalyticsTrackerSSE('/api/analytics/event');
let currentAnalyticsQueryId = null;

// Event delegation: Track all clicks on article links
document.addEventListener('click', (event) => {
    const link = event.target.closest('.btn-read-more, a[href]');
    if (!link) return;
    // ... (click tracking code)
});

// MutationObserver: Auto-track article displays
const articleObserver = new MutationObserver((mutations) => {
    // ... (display tracking code)
});

articleObserver.observe(document.getElementById('listView'), { childList: true, subtree: true });
articleObserver.observe(document.getElementById('timelineView'), { childList: true, subtree: true });

console.log('[Analytics] Tracker initialized');
// ==================== END ANALYTICS INITIALIZATION ====================
```

**Rationale:** Initialize tracker and set up automatic click/display tracking using event delegation and MutationObserver

---

#### Addition 3: Track search queries (Lines 1705-1708)
```javascript
async function performSearch() {
    const query = searchInput.value.trim();
    if (!query) return;

    // ADDED:
    // Analytics: Start tracking query
    currentAnalyticsQueryId = `query_${Date.now()}_${Math.random().toString(36).substring(2, 11)}`;
    analyticsTracker.startQuery(currentAnalyticsQueryId, query);
    console.log('[Analytics] Tracking query:', currentAnalyticsQueryId);

    // Hide initial state
    initialState.style.display = 'none';
```

**Rationale:** Track each search query with unique ID

---

#### Addition 4: Track chat queries (Lines 1833-1835)
```javascript
async function performFreeConversation(query) {
    // Add user message to chat
    addChatMessage('user', query);

    // ADDED:
    // Analytics: Track chat query
    currentAnalyticsQueryId = `chat_${Date.now()}_${Math.random().toString(36).substring(2, 11)}`;
    analyticsTracker.startQuery(currentAnalyticsQueryId, query);

    // Clear input
    searchInput.value = '';
```

**Rationale:** Track chat mode queries separately from search queries

---

### 5. Backend - Base Handler Query Logging
**File:** `code/python/core/baseHandler.py`
**Modified Lines:** 43-44, 264-281, 317-336, 343-359

**Changes Made:**

#### Addition 1: Import query logger (Lines 43-44)
```python
# ADDED:
# Analytics logging
from core.query_logger import get_query_logger
```

**Rationale:** Enable query logging in the main handler

---

#### Addition 2: Log query start (Lines 264-281)
```python
async def runQuery(self):
    print(f"========== NLWEBHANDLER.runQuery() CALLED ==========")
    logger.info(f"Starting query execution for conversation_id: {self.conversation_id}")

    # ADDED:
    # Analytics: Generate unique query ID and log query start
    self.query_id = f"query_{int(time.time() * 1000)}_{uuid.uuid4().hex[:8]}"
    query_logger = get_query_logger()
    query_start_time = time.time()

    try:
        query_logger.log_query_start(
            query_id=self.query_id,
            user_id=self.oauth_id or "anonymous",
            query_text=self.query,
            site=str(self.site) if isinstance(self.site, list) else self.site,
            mode=self.generate_mode or "list",
            decontextualized_query=self.decontextualized_query,
            conversation_id=self.conversation_id,
            model=self.model
        )
    except Exception as e:
        logger.warning(f"Failed to log query start: {e}")
```

**Rationale:** Track when each query starts with unique ID

---

#### Addition 3: Log query completion (Lines 317-336)
```python
# ADDED:
# Analytics: Log query completion
try:
    query_end_time = time.time()
    total_latency_ms = (query_end_time - query_start_time) * 1000

    num_results = 0
    if hasattr(self, 'final_ranked_answers') and self.final_ranked_answers:
        num_results = len(self.final_ranked_answers)

    query_logger.log_query_complete(
        query_id=self.query_id,
        latency_total_ms=total_latency_ms,
        num_results_retrieved=getattr(self, 'num_retrieved', 0),
        num_results_ranked=getattr(self, 'num_ranked', 0),
        num_results_returned=num_results,
        cost_usd=getattr(self, 'estimated_cost', 0),
        error_occurred=False
    )
except Exception as e:
    logger.warning(f"Failed to log query completion: {e}")
```

**Rationale:** Track query completion metrics and performance

---

#### Addition 4: Log query errors (Lines 343-359)
```python
except Exception as e:
    traceback.print_exc()

    # ADDED:
    # Analytics: Log query error
    try:
        query_end_time = time.time()
        total_latency_ms = (query_end_time - query_start_time) * 1000
        query_logger.log_query_complete(
            query_id=self.query_id,
            latency_total_ms=total_latency_ms,
            error_occurred=True,
            error_message=str(e)
        )
    except Exception as log_err:
        logger.warning(f"Failed to log query error: {log_err}")
```

**Rationale:** Track failed queries for debugging and analysis

---

### 6. Backend - Qdrant Retrieval Logging
**File:** `code/python/retrieval_providers/qdrant.py`
**Modified Lines:** 26-27, 850-917

**Changes Made:**

#### Addition 1: Import query logger (Lines 26-27)
```python
# ADDED:
# Analytics logging
from core.query_logger import get_query_logger
```

**Rationale:** Enable retrieval logging in Qdrant client

---

#### Addition 2: Log retrieved documents (Lines 850-917)
```python
# Format the results
results = self._format_results(top_results)

# ADDED:
# Analytics: Log retrieved documents with scores
handler = kwargs.get('handler')
if handler and hasattr(handler, 'query_id'):
    query_logger = get_query_logger()
    try:
        # Map scores back to results by URL
        # Handle both keyword-boosted and pure vector search cases
        score_map = {}

        if all_keywords and 'scored_results' in locals():
            # Keyword boosting was applied
            for final_score, point in scored_results[:num_results]:
                url = point.payload.get("url", "")
                if url:
                    score_map[url] = {
                        'vector_score': point.score,
                        'final_score': final_score,
                    }
        else:
            # Pure vector search - use top_results directly
            for point in top_results:
                url = point.payload.get("url", "")
                if url:
                    score_map[url] = {
                        'vector_score': point.score,
                        'final_score': point.score,
                    }

        # Log each retrieved document
        for position, result in enumerate(results):
            if len(result) >= 4:
                url = result[0]
                schema_json = result[1]
                name = result[2]
                site_name = result[3]

                score_data = score_map.get(url, {})
                vector_score = score_data.get('vector_score', 0.0)
                final_score = score_data.get('final_score', 0.0)

                # Parse description from schema_json
                description = ""
                try:
                    if schema_json:
                        schema_dict = json.loads(schema_json)
                        description = schema_dict.get('description', '') or schema_dict.get('articleBody', '')
                        if isinstance(description, list):
                            description = ' '.join(description)
                        description = description[:500] if description else ""
                except:
                    pass

                query_logger.log_retrieved_document(
                    query_id=handler.query_id,
                    doc_url=url,
                    doc_title=name,
                    doc_description=description,
                    retrieval_position=position,
                    vector_similarity_score=float(vector_score),
                    keyword_boost_score=0.0,
                    final_retrieval_score=float(final_score),
                    source='qdrant_hybrid_search'
                )

        logger.info(f"Analytics: Logged {len(results)} retrieved documents for query {handler.query_id}")
    except Exception as e:
        logger.warning(f"Failed to log retrieved documents: {e}")
```

**Rationale:** Track all retrieved documents with their vector similarity and boosted scores

---

### 7. Backend - Ranking Score Logging
**File:** `code/python/core/ranking.py`
**Modified Lines:** 21-22, 213-229

**Changes Made:**

#### Addition 1: Import query logger (Lines 21-22)
```python
# ADDED:
# Analytics logging
from core.query_logger import get_query_logger
```

**Rationale:** Enable ranking score logging

---

#### Addition 2: Log ranking scores (Lines 213-229)
```python
self.rankedAnswers.append(ansr)
logger.debug(f"Item {name} added to ranked answers")

# ADDED:
# Analytics: Log ranking score
if hasattr(self.handler, 'query_id'):
    query_logger = get_query_logger()
    try:
        # Get current position (will be updated after final sorting)
        current_position = len(self.rankedAnswers) - 1

        query_logger.log_ranking_score(
            query_id=self.handler.query_id,
            doc_url=url,
            ranking_position=current_position,
            llm_final_score=float(ranking.get("score", 0)),
            llm_snippet=ranking.get("description", ""),
            ranking_method='llm_fast_track' if self.ranking_type == Ranking.FAST_TRACK else 'llm_regular'
        )
    except Exception as log_err:
        logger.warning(f"Failed to log ranking score: {log_err}")
```

**Rationale:** Track LLM ranking scores for each document

---

### 8. Backend - Analytics Routes Registration
**File:** `code/python/webserver/routes/__init__.py`
**Modified Lines:** 12-16, 30-31

**Changes Made:**

#### Addition 1: Import analytics handler (Lines 12-16)
```python
# ADDED:
# Analytics routes (from parent webserver directory)
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from analytics_handler import register_analytics_routes
```

**Rationale:** Import analytics route registration function

---

#### Addition 2: Register analytics routes (Lines 30-31)
```python
def setup_routes(app):
    """Setup all routes for the application"""
    setup_static_routes(app)
    setup_api_routes(app)
    setup_health_routes(app)
    setup_mcp_routes(app)
    setup_a2a_routes(app)
    setup_conversation_routes(app)
    setup_chat_routes(app)
    setup_oauth_routes(app)

    # ADDED:
    # Register analytics routes
    register_analytics_routes(app)
```

**Rationale:** Enable analytics API endpoints in the webserver

---

## Rollback Instructions

### To Completely Remove Logging Infrastructure:

1. **Delete new files:**
   ```bash
   rm code/python/core/query_logger.py
   rm static/analytics-tracker.js
   rm static/analytics-dashboard.html
   rm code/python/webserver/analytics_handler.py
   rm LOGGING_IMPLEMENTATION_CHANGELOG.md
   ```

2. **Revert `static/json-renderer.js`:**
   - Remove line 4: `import { attachClickTracking, getAnalyticsTracker } from './analytics-tracker.js';`
   - Remove lines 22-23 (resultIndex property)
   - Remove lines 178-193 (analytics tracking code in createDefaultItemHtml)
   - Keep only the original `return container;` at line 176

3. **Revert `static/chat-interface-unified.js`:**
   - Remove line 8: `import { getAnalyticsTracker } from './analytics-tracker.js';`
   - Remove lines 394-396 (tracker initialization in WebSocket onopen)
   - Remove lines 617-621 (query tracking in sendMessage)

4. **Revert `static/news-search-prototype.html`:**
   - Remove lines 1145-1147 (analytics tracker script tag)
   - Remove lines 1199-1248 (analytics initialization block)
   - Remove lines 1705-1708 (query tracking in performSearch)
   - Remove lines 1833-1835 (query tracking in performFreeConversation)

5. **Revert `code/python/core/baseHandler.py`:**
   - Remove lines 43-44 (import query logger)
   - Remove lines 264-281 (query start logging)
   - Remove lines 317-336 (query completion logging)
   - Remove lines 343-359 (query error logging)

6. **Revert `code/python/retrieval_providers/qdrant.py`:**
   - Remove lines 26-27 (import query logger)
   - Remove lines 850-917 (retrieval logging block)

7. **Revert `code/python/core/ranking.py`:**
   - Remove lines 21-22 (import query logger)
   - Remove lines 213-229 (ranking score logging)

8. **Revert `code/python/webserver/routes/__init__.py`:**
   - Remove lines 12-16 (import analytics handler)
   - Remove lines 30-31 (register analytics routes call)

### To Disable Logging Without Removing Code:

1. **In `code/python/core/query_logger.py`:**
   - Change `_write_to_db()` to just `pass` (no-op)

2. **In `static/analytics-tracker.js`:**
   - Change `sendEvent()` to just `return` (no-op)

---

## Testing Checklist

- [ ] Query logger creates database and tables
- [ ] Frontend tracker initializes with WebSocket
- [ ] Queries are logged to database
- [ ] Clicks are tracked and sent to backend
- [ ] Dwell time is measured correctly
- [ ] Analytics dashboard loads and displays stats
- [ ] CSV export works
- [ ] No performance degradation in queries
- [ ] No errors in browser console
- [ ] No errors in backend logs

---

## Known Issues / Limitations

1. **Frontend integration:** User's actual frontend is `news-search-prototype.html` (standalone HTML with SSE, not WebSocket) - analytics tracker needs adaptation for SSE
2. **SSE vs WebSocket:** Analytics tracker was built for WebSocket, but frontend uses Server-Sent Events (SSE) - need to modify tracker to use HTTP POST instead
3. **Backend integration:** Need to integrate logging calls into:
   - `baseHandler.py` - Query start/end
   - `retriever.py` / `qdrant.py` - Retrieved documents
   - `ranking.py` - Ranking scores
4. **Analytics routes:** Need to register analytics routes in main webserver file

---

## Next Steps

1. Check actual frontend file: `news-search-prototype.html`
2. Integrate analytics tracker into correct frontend
3. Integrate logging into backend query pipeline
4. Add WebSocket analytics event handler
5. Register analytics API routes
6. Test end-to-end
7. Update CLAUDE.md and context.md with new architecture

---

## Dependencies Added

**Python:**
- None (all using stdlib)

**JavaScript:**
- None (vanilla JS modules)

**Database:**
- SQLite3 (already included in Python stdlib)

---

## Performance Impact

**Expected:**
- Async logging: <5ms overhead per query
- Frontend tracking: <1ms overhead per result render
- Database writes: Non-blocking (background thread)
- WebSocket messages: ~100 bytes per event

**Monitoring:**
- Check `latency_total_ms` in queries table
- Monitor database size growth
- Watch for WebSocket message queue buildup

---

## Security Considerations

1. **Privacy:**
   - No PII collection (as requested)
   - IP addresses should be hashed server-side (not yet implemented)
   - User IDs are anonymized

2. **Database:**
   - SQLite file permissions should be restricted
   - Consider encryption at rest for production

3. **API Endpoints:**
   - Analytics endpoints should require authentication (not yet implemented)
   - Rate limiting recommended for export endpoint

---

## Future Enhancements

1. Add authentication to analytics dashboard
2. Implement server-side IP hashing
3. Add data retention policies (auto-delete old logs)
4. Add database vacuum/optimization cron job
5. Migrate to PostgreSQL for production scale
6. Add real-time analytics with Redis
7. Add A/B testing framework

---

## File Size Impact

**Total new code:** ~2,400 lines
**Total modified code:** ~30 lines
**Database size (estimated):**
- 1,000 queries/day Ã— 7 days = ~5-10 MB
- With full feature vectors: ~20-30 MB per week

---

## Backup Recommendations

Before deploying to production:
1. Backup current codebase: `git commit -m "Pre-logging-implementation backup"`
2. Test on development/staging first
3. Monitor database growth for 1 week
4. Set up automated database backups

---

**End of Change Log**
