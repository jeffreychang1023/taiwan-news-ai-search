#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
update_architecture.py (NLWeb é©é…ç‰ˆ)
åŠŸèƒ½ï¼š
- å¾ architecture.html ä¸­è§£æ JavaScript graphData ç‰©ä»¶
- ä½¿ç”¨ YAML ç®¡ç†æ¨¡çµ„å±¤ç´š (level 0=group, level 1=module)
- è‡ªå‹•æª¢æ¸¬ Python æ¨¡çµ„é–“çš„ä¾è³´é—œä¿‚ (import edges)
- åˆ†æå¯¦ç¾ç‹€æ…‹ (done/partial/notdone)
- è¼¸å‡º graphData.json ä¾›è¦–è¦ºåŒ–ä½¿ç”¨
"""

from __future__ import annotations
import os
import sys
import re
import ast
import json
import yaml
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple, Set, Optional

# ---------------------
# é…ç½®å€ï¼šæ ¹æ“šä½ çš„å°ˆæ¡ˆçµæ§‹ä¿®æ”¹
# ---------------------
# æ³¨æ„ï¼šè…³æœ¬ä½æ–¼ scripts/ ç›®éŒ„ï¼Œè·¯å¾‘éœ€è¦ç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„
SCRIPT_DIR = Path(__file__).parent  # scripts/
PROJECT_ROOT = SCRIPT_DIR.parent     # NLWeb/

HTML_FILE = str(PROJECT_ROOT / "static" / "architecture.html")
MODULE_ROOT = str(PROJECT_ROOT / "code" / "python")
YAML_PATH = str(PROJECT_ROOT / "architecture_levels.yaml")
GRAPH_JSON = str(PROJECT_ROOT / "graphData.json")
LAYOUT_JSON = str(PROJECT_ROOT / "architecture-diagram.json")  # ä½ˆå±€å‚™ä»½

# ---------------------
# Fallback builtin level map (æœ€å¾Œæ‰‹æ®µ)
# ---------------------
FALLBACK_BUILTIN_MAP = {
    # Module headers (level 0)
    "mod-storage": 0, "mod-retrieval": 0, "mod-ranking": 0,
    "mod-search": 0, "mod-reasoning": 0, "mod-output": 0, "mod-others": 0,
    # Regular modules (level 1)
    "sys-db": 1, "sys-cache": 1, "internal-index": 1, "sys-vec": 1,
    "web-search-api": 1, "mmr": 1, "weight-calibrator": 1, "xgboost-ranker": 1,
}

STATUS_PATTERNS = ["TODO", "NotImplementedError", "pass"]

# ---------------------
# Helpers
# ---------------------
def read_file(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def iso_now() -> str:
    return datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

def load_yaml(path: str) -> Dict:
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f) or {}
    return {}

def save_yaml(path: str, data: Dict):
    with open(path, "w", encoding="utf-8") as f:
        yaml.safe_dump(data, f, allow_unicode=True, sort_keys=False)

def ensure_yaml_levels_section(yaml_data: Dict):
    if "levels" not in yaml_data or not isinstance(yaml_data["levels"], dict):
        yaml_data["levels"] = {}

# ---------------------
# è§£æ HTML ä¸­çš„ JavaScript graphData
# ---------------------
def parse_graphdata_from_html(html_path: str) -> Tuple[List[Dict], List[Dict]]:
    """
    å¾ architecture.html çš„ <script> æ¨™ç±¤ä¸­æå– graphData
    è¿”å›: (nodes, groups)
    """
    if not os.path.exists(html_path):
        print(f"[ERROR] {html_path} not found.")
        sys.exit(1)

    text = read_file(html_path)

    # 1. æå– graphData = { ... }; å€å¡Š
    match = re.search(r'const graphData\s*=\s*\{([\s\S]*?)\n\s*\};', text)
    if not match:
        print("[ERROR] Cannot find 'const graphData = {...};' in HTML")
        sys.exit(1)

    graphdata_content = match.group(1)

    # 2. æå– nodes é™£åˆ—ï¼ˆæ”¯æ´ JavaScript å’Œ JSON æ ¼å¼ï¼‰
    # JavaScript: nodes: [...]
    # JSON: "nodes": [...]
    nodes_match = re.search(r'["\']?nodes["\']?\s*:\s*\[([\s\S]*?)\]\s*,\s*["\']?edges["\']?\s*:', graphdata_content)
    if not nodes_match:
        print("[ERROR] Cannot find 'nodes: [...]' or '\"nodes\": [...]' in graphData")
        sys.exit(1)

    nodes_str = nodes_match.group(1)

    # 3. è§£ææ¯å€‹ç¯€é»ç‰©ä»¶ï¼ˆæ”¯æ´ JavaScript å’Œ JSON æ ¼å¼ï¼‰
    # JavaScript: { id: 'sys-db', labelEn: 'Postgres DB', ... }
    # JSON: { "id": "sys-db", "labelEn": "Postgres DB", ... }

    parsed_nodes = []
    groups_dict = {}  # moduleId -> group info

    # ä½¿ç”¨æ›´éˆæ´»çš„æ–¹å¼ï¼šé€å€‹åŒ¹é…ç‰©ä»¶
    # å…ˆæ‰¾å‡ºæ‰€æœ‰ {...} å€å¡Š
    object_pattern = r'\{[^}]*?"id"[^}]*?\}'

    for obj_match in re.finditer(object_pattern, nodes_str, re.DOTALL):
        obj_str = obj_match.group(0)

        # æå–å„å€‹æ¬„ä½
        id_match = re.search(r'["\']?id["\']?\s*:\s*["\']([^"\']+)["\']', obj_str)
        labelEn_match = re.search(r'["\']?labelEn["\']?\s*:\s*["\']([^"\']+)["\']', obj_str)
        labelZh_match = re.search(r'["\']?labelZh["\']?\s*:\s*["\']([^"\']+)["\']', obj_str)
        moduleId_match = re.search(r'["\']?moduleId["\']?\s*:\s*(\d+)', obj_str)
        isModuleHeader_match = re.search(r'["\']?isModuleHeader["\']?\s*:\s*(true|false)', obj_str)
        status_match = re.search(r'["\']?status["\']?\s*:\s*["\']([^"\']+)["\']', obj_str)
        script_match = re.search(r'["\']?script["\']?\s*:\s*["\']([^"\']*)["\']', obj_str)
        rationale_match = re.search(r'["\']?rationale["\']?\s*:\s*["\']([^"\']*)["\']', obj_str)

        if not (id_match and labelEn_match and labelZh_match and moduleId_match):
            continue

        node_id = id_match.group(1)
        labelEn = labelEn_match.group(1)
        labelZh = labelZh_match.group(1)
        moduleId = int(moduleId_match.group(1))

        # åˆ¤æ–·æ˜¯å¦ç‚º module headerï¼š
        # 1. æœ‰ isModuleHeader: true
        # 2. æˆ– ID ä»¥ mod- é–‹é ­
        isModuleHeader = False
        if isModuleHeader_match and isModuleHeader_match.group(1) == 'true':
            isModuleHeader = True
        elif node_id.startswith('mod-'):
            isModuleHeader = True

        status = status_match.group(1) if status_match else 'unknown'
        script = script_match.group(1) if script_match else ''
        rationale = rationale_match.group(1) if rationale_match else ''

        # å»ºç«‹ç¯€é»è³‡æ–™
        node_data = {
            "node_id": node_id,
            "labelEn": labelEn,
            "labelZh": labelZh,
            "script": script,
            "status": status,
            "rationale": rationale,
            "moduleId": moduleId,
            "isModuleHeader": isModuleHeader,
            "parent_group": None,
            "level": None
        }

        parsed_nodes.append(node_data)

        # å»ºç«‹ç¾¤çµ„æ˜ å°„
        if isModuleHeader:
            groups_dict[moduleId] = {
                "id": node_id,
                "labelEn": labelEn,
                "labelZh": labelZh,
                "level": 0,  # Module headers éƒ½æ˜¯ level 0
                "children": []
            }

    # 4. åˆ†é…ç¯€é»åˆ°å°æ‡‰çš„ç¾¤çµ„
    for node in parsed_nodes:
        if not node["isModuleHeader"]:
            mid = node["moduleId"]
            if mid in groups_dict:
                groups_dict[mid]["children"].append(node["node_id"])
                node["parent_group"] = groups_dict[mid]["id"]

    groups = list(groups_dict.values())

    print(f"[INFO] Parsed {len(parsed_nodes)} nodes and {len(groups)} groups from HTML")
    return parsed_nodes, groups

# ---------------------
# Level åˆ¤æ–·é‚è¼¯
# ---------------------
def determine_levels_by_group(nodes: List[Dict], groups: List[Dict], yaml_data: Dict) -> Tuple[List[Dict], List[Dict]]:
    """
    å„ªå…ˆç´šï¼š
    1. YAML levels: å€æ®µ
    2. HTML moduleId (isModuleHeader=true â†’ level 0, children â†’ level 1)
    3. YAML builtin: å€æ®µ
    4. FALLBACK_BUILTIN_MAP
    """
    ensure_yaml_levels_section(yaml_data)
    yaml_levels = yaml_data.get("levels") or {}

    # è™•ç† groups
    group_map = {g["id"]: g for g in groups}

    # YAML override for groups
    for key, val in yaml_levels.items():
        if isinstance(val, dict) and "children" in val:
            gid = key
            if gid in group_map:
                if isinstance(val.get("level"), int):
                    group_map[gid]["level"] = val["level"]
                yaml_children = val.get("children") or []
                existing = set(group_map[gid]["children"])
                for c in yaml_children:
                    if c not in existing:
                        group_map[gid]["children"].append(c)

    # è™•ç† nodes
    node_map = {n["node_id"]: n for n in nodes}

    for nid, node in node_map.items():
        # Module headers æ°¸é æ˜¯ level 0
        if node.get("isModuleHeader"):
            node["level"] = 0
            continue

        # 1. YAML levels: å„ªå…ˆ
        if nid in yaml_levels and isinstance(yaml_levels[nid], dict):
            lv = yaml_levels[nid].get("level")
            if isinstance(lv, int):
                node["level"] = lv
                continue

        # 2. å¦‚æœæ˜¯ group çš„ childï¼Œé è¨­ level 1
        if node.get("parent_group"):
            node["level"] = 1
            continue

        # 3. YAML builtin:
        builtin_lv = yaml_data.get("builtin", {}).get(nid)
        if builtin_lv is not None:
            node["level"] = builtin_lv
            continue

        # 4. ç¡¬ç·¨ç¢¼ fallback
        if nid in FALLBACK_BUILTIN_MAP:
            node["level"] = FALLBACK_BUILTIN_MAP[nid]
            continue

        # 5. ç„¡æ³•æ±ºå®šï¼Œç•™å¾… CLI è¼¸å…¥
        node["level"] = None

    return list(node_map.values()), list(group_map.values())

# ---------------------
# CLI æ‰¹é‡ level è³¦å€¼
# ---------------------
def cli_batch_assign_levels(unassigned_nodes: List[Dict], yaml_data: Dict) -> Tuple[List[Dict], List[str]]:
    assigned, skipped = [], []
    if not unassigned_nodes:
        return assigned, skipped

    print("\n[NOTICE] Nodes without level (éœ€è¦æ‰‹å‹•æŒ‡å®š):")
    for i, n in enumerate(unassigned_nodes, 1):
        print(f"{i}. {n['node_id']} ({n.get('labelZh','')}) script={n.get('script','')}")

    inp = input("Enter levels (all 1 / 1,0,1 / skip): ").strip()

    if inp == "":
        skipped = [n["node_id"] for n in unassigned_nodes]
        return assigned, skipped

    # all 1 æˆ– all 0
    if inp.lower().startswith("all"):
        parts = inp.split()
        if len(parts) == 2 and parts[1] in ("0", "1"):
            lv = int(parts[1])
            for n in unassigned_nodes:
                n["level"] = lv
                assigned.append(n)
                ensure_yaml_levels_section(yaml_data)
                yaml_data["levels"].setdefault(n["node_id"], {})
                yaml_data["levels"][n["node_id"]]["level"] = lv
                if not yaml_data["levels"][n["node_id"]].get("label"):
                    yaml_data["levels"][n["node_id"]]["label"] = n.get("labelZh","")
            return assigned, skipped

    # é€—è™Ÿåˆ†éš”åˆ—è¡¨
    tokens = re.split(r"[\s,]+", inp)
    if len(tokens) == len(unassigned_nodes):
        for tok, n in zip(tokens, unassigned_nodes):
            if tok.lower() in ("skip", "s", ""):
                skipped.append(n["node_id"])
                continue
            if tok not in ("0", "1"):
                skipped.append(n["node_id"])
                continue
            lv = int(tok)
            n["level"] = lv
            assigned.append(n)
            ensure_yaml_levels_section(yaml_data)
            yaml_data["levels"].setdefault(n["node_id"], {})
            yaml_data["levels"][n["node_id"]]["level"] = lv
            if not yaml_data["levels"][n["node_id"]].get("label"):
                yaml_data["levels"][n["node_id"]]["label"] = n.get("labelZh","")
        return assigned, skipped

    # é€å€‹è©¢å•
    for n in unassigned_nodes:
        while True:
            ans = input(f"Set level for {n['node_id']} (0/1/skip): ").strip().lower()
            if ans in ("skip", ""):
                skipped.append(n["node_id"])
                break
            if ans in ("0","1"):
                lv = int(ans)
                n["level"] = lv
                assigned.append(n)
                ensure_yaml_levels_section(yaml_data)
                yaml_data["levels"].setdefault(n["node_id"], {})
                yaml_data["levels"][n["node_id"]]["level"] = lv
                if not yaml_data["levels"][n["node_id"]].get("label"):
                    yaml_data["levels"][n["node_id"]]["label"] = n.get("labelZh","")
                break
            print("Enter 0/1 or skip")

    return assigned, skipped

# ---------------------
# æ¨¡ç³Šæª”æ¡ˆæœå°‹
# ---------------------
def find_file_fuzzy(path):
    """åœ¨ MODULE_ROOT ä¸­æ¨¡ç³Šæœå°‹æª”æ¡ˆ"""
    if not path:
        return None

    # 1. å®Œæ•´è·¯å¾‘
    full_path = os.path.join(MODULE_ROOT, path)
    if os.path.exists(full_path):
        return full_path

    # 2. å˜—è©¦åŠ ä¸Š .py
    if not path.endswith('.py'):
        py_path = os.path.join(MODULE_ROOT, path + '.py')
        if os.path.exists(py_path):
            return py_path

    # 3. æœå°‹æª”å
    base = os.path.basename(path)
    for root, dirs, files in os.walk(MODULE_ROOT):
        if base in files:
            return os.path.join(root, base)
        if base + '.py' in files:
            return os.path.join(root, base + '.py')

    return None

# ---------------------
# å»ºç«‹è…³æœ¬æŸ¥æ‰¾è¡¨
# ---------------------
def build_script_lookup(nodes: List[Dict]) -> Dict[str, str]:
    """å»ºç«‹ script è·¯å¾‘ â†’ node_id çš„æ˜ å°„"""
    script_map = {}  # å®Œæ•´è·¯å¾‘
    module_map = {}  # module.path.format
    basename_map = {}  # æª”å

    for n in nodes:
        nid = n["node_id"]
        script = (n.get("script") or "").strip()
        if not script:
            basename_map[nid] = nid  # è®“ node_id è‡ªå·±ä¹Ÿèƒ½åŒ¹é…
            continue

        # æ­£è¦åŒ–è·¯å¾‘
        s_norm = script.replace("\\", "/").lstrip("./")
        script_map[s_norm] = nid

        # å»ºç«‹ module æ ¼å¼æ˜ å°„
        if s_norm.endswith(".py"):
            mod_path = s_norm[:-3]
            dotted = mod_path.replace("/", ".")
            module_map[dotted] = nid
            basename_map[os.path.basename(mod_path)] = nid
        else:
            basename_map[os.path.splitext(os.path.basename(s_norm))[0]] = nid

        # ä¹ŸåŠ å…¥ node_id æ˜ å°„
        basename_map[nid] = nid

    return {"script_exact": script_map, "module": module_map, "basename": basename_map}

# ---------------------
# Edge æª¢æ¸¬ (ä¾è³´é—œä¿‚åˆ†æ)
# ---------------------
def detect_edges_refined(nodes: List[Dict]) -> List[Dict]:
    """ä½¿ç”¨ AST åˆ†æ Python import é—œä¿‚"""
    lookup_maps = build_script_lookup(nodes)
    script_exact_map = lookup_maps["script_exact"]
    module_map = lookup_maps["module"]
    basename_map = lookup_maps["basename"]

    edges_set: Set[Tuple[str,str]] = set()

    for n in nodes:
        src_id = n["node_id"]
        script = (n.get("script") or "").strip()
        if not script:
            continue

        file_path = find_file_fuzzy(script)
        if not file_path:
            continue

        try:
            src = read_file(file_path)
            tree = ast.parse(src, filename=file_path)
        except SyntaxError as e:
            print(f"[WARNING] Syntax error in {file_path}: {e}")
            continue
        except Exception as e:
            print(f"[WARNING] Failed to parse {file_path}: {e}")
            continue

        # åˆ†æ import
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imported = alias.name
                    candidates = [imported, imported.split(".")[-1]]
                    for cand in candidates:
                        if cand in module_map:
                            tgt = module_map[cand]
                            if tgt != src_id:
                                edges_set.add((src_id, tgt))
                                break
                        elif cand in basename_map:
                            tgt = basename_map[cand]
                            if tgt != src_id:
                                edges_set.add((src_id, tgt))
                                break

            elif isinstance(node, ast.ImportFrom):
                module = node.module or ""
                if module in module_map:
                    tgt = module_map[module]
                    if tgt != src_id:
                        edges_set.add((src_id, tgt))

                for alias in node.names:
                    name = alias.name
                    if name in module_map:
                        tgt = module_map[name]
                        if tgt != src_id:
                            edges_set.add((src_id, tgt))
                    elif name in basename_map:
                        tgt = basename_map[name]
                        if tgt != src_id:
                            edges_set.add((src_id, tgt))

    return [{"from": f, "to": t} for f, t in sorted(edges_set)]

def detect_edges_from_dataflow(nodes: List[Dict]) -> List[Dict]:
    """åŸºæ–¼å·²çŸ¥çš„ç³»çµ±æ•¸æ“šæµç”Ÿæˆ edges

    é€™å€‹å‡½æ•¸å®šç¾©äº†ç³»çµ±å¯¦éš›çš„åŸ·è¡Œæµç¨‹å’Œæ•¸æ“šæµå‘ï¼Œ
    è€Œä¸åªæ˜¯ç¨‹å¼ç¢¼çš„ import ä¾è³´é—œä¿‚ã€‚

    Returns:
        List[Dict]: æ•¸æ“šæµ edges
    """
    # å»ºç«‹ node_id é›†åˆï¼Œç”¨æ–¼éæ¿¾
    node_ids = {n["node_id"] for n in nodes}

    # å®šç¾©å®Œæ•´çš„æ•¸æ“šæµï¼ˆåŸºæ–¼ generate_answer.py å’Œç³»çµ±æ¶æ§‹ï¼‰
    dataflow_edges = [
        # A. Input Layer â†’ Retrieval (3æ¢)
        ("sys-api", "query-decomp"),          # API ç™¼èµ·æŸ¥è©¢æ‹†è§£
        ("sys-api", "knowledge-gap"),         # ä¸¦è¡ŒåŸ·è¡Œéœ€æ±‚åµæ¸¬
        ("query-decomp", "internal-index"),   # æ‹†è§£å¾Œé€åˆ°æª¢ç´¢

        # B. Retrieval Layer â†” Storage (4æ¢)
        ("internal-index", "sys-vec"),        # æŸ¥è©¢å‘é‡è³‡æ–™åº«
        ("internal-index", "sys-db"),         # æŸ¥è©¢é—œè¯å¼è³‡æ–™åº«
        ("sys-vec", "internal-index"),        # å‘é‡çµæœè¿”å›
        ("sys-db", "internal-index"),         # è³‡æ–™åº«çµæœè¿”å›

        # C. Retrieval â†’ Ranking (2æ¢)
        ("internal-index", "xgboost"),        # æª¢ç´¢çµæœé€åˆ°MLæ’åº
        ("xgboost", "mmr"),                   # æ’åºçµæœé€åˆ°å¤šæ¨£æ€§éæ¿¾

        # D. Ranking â†’ Reasoning (2æ¢)
        ("mmr", "evidence-chain"),            # éæ¿¾å¾Œæ§‹å»ºè­‰æ“šéˆ
        ("evidence-chain", "synthesis"),      # è­‰æ“šé€åˆ°ç¶œåˆæ¨¡çµ„

        # E. Reasoning â†” LLM â†’ Output (4æ¢)
        ("synthesis", "sys-llm"),             # å‘¼å«LLMç”Ÿæˆç­”æ¡ˆ
        ("sys-llm", "synthesis"),             # LLMçµæœè¿”å›
        ("synthesis", "sys-api"),             # ç­”æ¡ˆè¿”å›API
        ("sys-api", "sys-fe"),                # APIé€åˆ°å‰ç«¯é¡¯ç¤º

        # F. Infrastructure Support (3æ¢)
        ("prompt-guardrails", "sys-llm"),     # å®‰å…¨æª¢æŸ¥ä¿è­·LLM
        ("xgboost", "sys-ana"),               # è¨˜éŒ„æ’åºæ•¸æ“š
        ("sys-ana", "sys-db"),                # åˆ†ææ•¸æ“šå­˜å…¥è³‡æ–™åº«

        # G. Additional flows (å¯é¸ï¼Œè¦–éœ€æ±‚å•Ÿç”¨)
        # ("sys-api", "domain-classifier"),   # é ˜åŸŸåˆ†é¡
        # ("domain-classifier", "internal-index"),
        # ("sys-cache", "internal-index"),    # Cache åŠ é€Ÿ
        # ("internal-index", "sys-cache"),
        # ("knowledge-gap", "iterative-search"), # éè¿´æœå°‹
        # ("iterative-search", "internal-index"),
        # ("internal-index", "web-search"),   # ç¶²è·¯æœå°‹
        # ("web-search", "mmr"),
    ]

    # åªä¿ç•™å…©ç«¯ç¯€é»éƒ½å­˜åœ¨çš„ edges
    valid_edges = []
    for from_id, to_id in dataflow_edges:
        if from_id in node_ids and to_id in node_ids:
            valid_edges.append({"from": from_id, "to": to_id})

    print(f"[INFO] Generated {len(valid_edges)} dataflow edges (from {len(dataflow_edges)} defined flows)")

    return valid_edges

# ---------------------
# ç‹€æ…‹åˆ†æ
# ---------------------
def analyze_status(nodes: List[Dict]):
    """åˆ†æ Python æ¨¡çµ„å¯¦ç¾ç‹€æ…‹

    ç­–ç•¥ï¼š
    - å¦‚æœæª”æ¡ˆå­˜åœ¨ â†’ è‡ªå‹•åµæ¸¬ status (done/partial)
    - å¦‚æœæª”æ¡ˆä¸å­˜åœ¨ â†’ ä¿ç•™åŸæœ‰ statusï¼ˆå¯èƒ½æ˜¯æ‰‹å‹•è¨­å®šçš„æœªä¾†æ¨¡çµ„ï¼‰
    """
    for n in nodes:
        # Module headers æ²’æœ‰å¯¦ç¾
        if n.get("isModuleHeader"):
            n["status"] = "header"
            continue

        script = (n.get("script") or "").strip()
        if not script:
            # æ²’æœ‰ script è·¯å¾‘ï¼šä¿ç•™åŸ status æˆ–è¨­ç‚º notdone
            if not n.get("status") or n.get("status") == "unknown":
                n["status"] = "notdone"
            continue

        script_path = find_file_fuzzy(script)
        if not script_path:
            # æª”æ¡ˆä¸å­˜åœ¨ï¼šä¿ç•™åŸ statusï¼ˆå¯èƒ½æ˜¯æ‰‹å‹•è¨­å®šçš„æœªä¾†æ¨¡çµ„ï¼‰
            if not n.get("status") or n.get("status") == "unknown":
                n["status"] = "notdone"
            continue

        # æª”æ¡ˆå­˜åœ¨ï¼šè‡ªå‹•åµæ¸¬ status
        try:
            src = read_file(script_path)
            tree = ast.parse(src, filename=script_path)
        except Exception:
            n["status"] = "partial"
            continue

        status = "done"
        src_lines = src.splitlines()

        # æª¢æŸ¥æ˜¯å¦æœ‰ pass, TODO, NotImplementedError
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
                # æª¢æŸ¥å‡½æ•¸/é¡åˆ¥é«”æ˜¯å¦åªæœ‰ pass
                if any(isinstance(x, ast.Pass) for x in ast.walk(node)):
                    status = "partial"
                    break

                # æª¢æŸ¥åŸå§‹ç¢¼
                start = getattr(node, "lineno", None)
                end = getattr(node, "end_lineno", None)
                if start and end:
                    slice_text = "\n".join(src_lines[start-1:end])
                    if any(p in slice_text for p in STATUS_PATTERNS):
                        status = "partial"
                        break

        # å…¨å±€æª¢æŸ¥
        if status == "done" and any(p in src for p in STATUS_PATTERNS):
            status = "partial"

        n["status"] = status

# ---------------------
# YAML æ›´æ–°
# ---------------------
def update_yaml_entries(yaml_data: Dict, nodes: List[Dict], groups: List[Dict]) -> Tuple[int, int]:
    """æ›´æ–° YAML é…ç½®"""
    ensure_yaml_levels_section(yaml_data)
    new_cnt, updated_cnt = 0, 0
    levels_section = yaml_data["levels"]

    # æ›´æ–° groups
    for g in groups:
        gid = g["id"]
        if gid not in levels_section:
            levels_section[gid] = {
                "level": g.get("level", 0),
                "children": g.get("children", []),
                "label": g.get("labelZh", ""),
                "description": ""
            }
            new_cnt += 1
        else:
            existing = levels_section[gid]
            changed = False
            existing_children = set(existing.get("children", []) or [])
            for c in g.get("children", []):
                if c not in existing_children:
                    existing.setdefault("children", []).append(c)
                    changed = True
            if changed:
                updated_cnt += 1

    # æ›´æ–° nodes
    for n in nodes:
        nid = n["node_id"]
        lvl = n.get("level")
        label = n.get("labelZh", "")

        if nid not in levels_section:
            levels_section[nid] = {
                "level": lvl if isinstance(lvl, int) else None,
                "label": label,
                "description": ""
            }
            new_cnt += 1
        else:
            existing = levels_section[nid]
            changed = False
            if existing.get("level") is None and isinstance(lvl, int):
                existing["level"] = lvl
                changed = True
            if not existing.get("label") and label:
                existing["label"] = label
                changed = True
            if changed:
                updated_cnt += 1

    return new_cnt, updated_cnt

# ---------------------
# åµæ¸¬è¢«ç§»é™¤çš„ YAML æ¢ç›®
# ---------------------
def detect_removed_yaml_entries(yaml_data: Dict, nodes: List[Dict], groups: List[Dict]) -> List[str]:
    """åµæ¸¬ YAML ä¸­å­˜åœ¨ä½† HTML ä¸­ä¸å­˜åœ¨çš„æ¢ç›®"""
    ensure_yaml_levels_section(yaml_data)
    parsed_ids = {n["node_id"] for n in nodes}
    parsed_group_ids = {g["id"] for g in groups}
    removed = []

    for key in list(yaml_data["levels"].keys()):
        if key not in parsed_ids and key not in parsed_group_ids:
            removed.append(key)

    return removed

# ---------------------
# è¼‰å…¥èˆŠä½ˆå±€
# ---------------------
def load_layout_from_json(layout_path: str) -> tuple:
    """å¾ architecture-diagram.json è¼‰å…¥èˆŠçš„ä½ˆå±€åº§æ¨™ã€moduleBoxes å’Œ edges

    Returns:
        tuple: (old_layout dict, moduleBoxes list, edges list, layout_data dict)
    """
    old_layout = {}
    module_boxes = []
    edges = []
    layout_data = {}  # ä¿å­˜å®Œæ•´æ•¸æ“šä»¥ä¾›å¾ŒçºŒä½¿ç”¨

    if not os.path.exists(layout_path):
        return old_layout, module_boxes, edges, layout_data

    try:
        with open(layout_path, 'r', encoding='utf-8') as f:
            layout_data = json.load(f)

        # å»ºç«‹ node_id â†’ {x, y} æ˜ å°„
        for node in layout_data.get('nodes', []):
            if node.get('x') is not None and node.get('y') is not None:
                old_layout[node['id']] = {
                    'x': node['x'],
                    'y': node['y']
                }

        # ä¿ç•™ moduleBoxes
        module_boxes = layout_data.get('moduleBoxes', [])

        # ä¿ç•™ edges
        edges = layout_data.get('edges', [])

        print(f"[INFO] Loaded layout for {len(old_layout)} nodes from {os.path.basename(layout_path)}")
        if module_boxes:
            print(f"[INFO] Loaded {len(module_boxes)} module boxes from {os.path.basename(layout_path)}")
        if edges:
            print(f"[INFO] Loaded {len(edges)} edges from {os.path.basename(layout_path)}")
    except Exception as e:
        print(f"[WARNING] Could not load layout: {e}")

    return old_layout, module_boxes, edges, layout_data

# ---------------------
# çµ„åˆ graphData.json
# ---------------------
def compose_graph_data(nodes: List[Dict], groups: List[Dict], edges: List[Dict]) -> Dict:
    """çµ„åˆæœ€çµ‚çš„ graphData.jsonï¼Œä¸¦ä¿ç•™èˆŠä½ˆå±€åº§æ¨™ã€moduleBoxes å’Œ edges"""

    # 1. è¼‰å…¥èˆŠä½ˆå±€ã€moduleBoxesã€edges å’Œå®Œæ•´æ•¸æ“š
    old_layout, module_boxes, old_edges, layout_data = load_layout_from_json(LAYOUT_JSON)

    # 2. çµ„åˆ groups
    group_nodes = []
    for g in groups:
        group_nodes.append({
            "id": g["id"],
            "type": "group",
            "labelEn": g.get("labelEn", g["id"]),
            "labelZh": g.get("labelZh", ""),
            "level": g.get("level", 0),
            "children": g.get("children", [])
        })

    # 3. çµ„åˆ nodesï¼Œä¿ç•™åº§æ¨™
    module_nodes = []
    preserved_count = 0
    processed_node_ids = set()

    for n in nodes:
        node_id = n["node_id"]
        processed_node_ids.add(node_id)

        node_data = {
            "id": node_id,
            "labelEn": n.get("labelEn", node_id),
            "labelZh": n.get("labelZh", ""),
            "moduleId": n.get("moduleId"),
            "status": n.get("status", "unknown"),
            "rationale": n.get("rationale", ""),
            "script": n.get("script", "")
        }

        # ä¿ç•™ isModuleHeader
        if n.get("isModuleHeader"):
            node_data["isModuleHeader"] = True

        # 4. ä¿ç•™èˆŠåº§æ¨™
        if node_id in old_layout:
            node_data["x"] = old_layout[node_id]["x"]
            node_data["y"] = old_layout[node_id]["y"]
            preserved_count += 1

            # ä¿ç•™ workflows æ¬„ä½ï¼ˆå¾ layout_data æŸ¥æ‰¾ï¼‰
            if layout_data:
                old_node = next((node for node in layout_data.get('nodes', [])
                                 if node.get('id') == node_id), None)
                if old_node and 'workflows' in old_node:
                    node_data['workflows'] = old_node['workflows']
        else:
            # æ–°ç¯€é»æ²’æœ‰åº§æ¨™ï¼ˆç€è¦½å™¨æœƒè‡ªå‹•è¨ˆç®—ï¼‰
            node_data["x"] = None
            node_data["y"] = None

        module_nodes.append(node_data)

    # ğŸ†• ä¿ç•™ JSON ä¸­å­˜åœ¨ä½† HTML ä¸­ä¸å­˜åœ¨çš„ç¯€é»ï¼ˆæ‰‹å‹•æ–°å¢çš„ç¯€é»ï¼‰
    if layout_data:
        for old_node in layout_data.get('nodes', []):
            old_node_id = old_node.get('id')
            if old_node_id and old_node_id not in processed_node_ids:
                # é€™æ˜¯æ‰‹å‹•æ–°å¢çš„ç¯€é»ï¼Œå®Œæ•´ä¿ç•™
                preserved_node = {
                    "id": old_node_id,
                    "labelEn": old_node.get("labelEn", old_node_id),
                    "labelZh": old_node.get("labelZh", ""),
                    "moduleId": old_node.get("moduleId", 0),
                    "status": old_node.get("status", "notdone"),
                    "rationale": old_node.get("rationale", ""),
                    "script": old_node.get("script", ""),
                    "x": old_node.get("x"),
                    "y": old_node.get("y")
                }
                if old_node.get("isModuleHeader"):
                    preserved_node["isModuleHeader"] = True
                if "workflows" in old_node:
                    preserved_node["workflows"] = old_node["workflows"]

                module_nodes.append(preserved_node)
                print(f"[INFO] Preserved manually-added node: {old_node_id} ({old_node.get('labelZh', '')})")

    if preserved_count > 0:
        print(f"[INFO] Preserved layout for {preserved_count}/{len(nodes)} nodes")

    # 5. æ±ºå®šä½¿ç”¨å“ªäº› edgesï¼š
    #    æ–¹æ¡ˆ Aï¼šå®Œå…¨ä¿¡ä»» JSONï¼Œåªåœ¨åˆå§‹åŒ–æ™‚ä½¿ç”¨ dataflow
    #    - å„ªå…ˆä½¿ç”¨ architecture-diagram.json çš„ edgesï¼ˆå°Šé‡æ‰‹å‹•ç·¨è¼¯ï¼‰
    #    - åªåœ¨æ²’æœ‰èˆŠ edges æ™‚æ‰ä½¿ç”¨ dataflow åˆå§‹åŒ–
    valid_node_ids = {n["id"] for n in module_nodes}

    if old_edges:
        # ä½¿ç”¨èˆŠçš„ edges ä½œç‚ºåŸºç¤ï¼ˆå°Šé‡æ‰‹å‹•ç·¨è¼¯ï¼šæ–°å¢ã€åˆªé™¤éƒ½ä¿ç•™ï¼‰
        valid_old_edges = [
            e for e in old_edges
            if e.get("from") in valid_node_ids and e.get("to") in valid_node_ids
        ]

        removed_edges_count = len(old_edges) - len(valid_old_edges)
        if removed_edges_count > 0:
            print(f"[INFO] Removed {removed_edges_count} invalid edges (nodes not found)")

        final_edges = valid_old_edges
        print(f"[INFO] Using {len(final_edges)} edges from architecture-diagram.json (æ‰‹å‹•ç·¨è¼¯å·²ä¿ç•™)")
    else:
        # æ²’æœ‰èˆŠ edgesï¼Œä½¿ç”¨ dataflow åˆå§‹åŒ–ï¼ˆé¦–æ¬¡åŸ·è¡Œï¼‰
        final_edges = edges if edges else []
        print(f"[INFO] Initialized {len(final_edges)} edges from dataflow definition (é¦–æ¬¡åˆå§‹åŒ–)")

    # 6. çµ„åˆå®Œæ•´çš„ graphDataï¼ˆåŒ…å« moduleBoxesï¼‰
    result = {
        "nodes": module_nodes,
        "edges": final_edges
    }

    # åªæœ‰åœ¨æœ‰ moduleBoxes çš„æ™‚å€™æ‰åŠ å…¥
    if module_boxes:
        result["moduleBoxes"] = module_boxes

    return result

# ---------------------
# ä¿®å¾© JSON ä¸­çš„æ›è¡Œç¬¦ï¼ˆç”¨æ–¼åµŒå…¥ HTMLï¼‰
# ---------------------
def escape_newlines_in_json(json_str: str) -> str:
    """
    å°‡ JSON å­—ç¬¦ä¸²å€¼å…§çš„å¯¦éš›æ›è¡Œç¬¦æ›¿æ›ç‚º \\n è½‰ç¾©åºåˆ—

    é€™æ˜¯ç‚ºäº†é¿å…å°‡ JSON åµŒå…¥ HTML <script> æ™‚å‡ºç¾ JavaScript èªæ³•éŒ¯èª¤
    """
    result = []
    in_string = False
    backslash = chr(92)  # '\'
    quote = chr(34)      # '"'
    newline = chr(10)    # '\n'

    for i, char in enumerate(json_str):
        prev = json_str[i-1] if i > 0 else ''

        # æª¢æ¸¬å­—ç¬¦ä¸²é‚Šç•Œï¼ˆå¿½ç•¥è½‰ç¾©çš„å¼•è™Ÿ \"ï¼‰
        if char == quote and prev != backslash:
            in_string = not in_string
            result.append(char)
        # åœ¨å­—ç¬¦ä¸²å…§é‡åˆ°æ›è¡Œç¬¦ï¼Œæ›¿æ›ç‚º \n
        elif in_string and char == newline:
            result.append(backslash + 'n')
        else:
            result.append(char)

    return ''.join(result)


# ---------------------
# æ›´æ–° HTML ä¸­çš„ graphData
# ---------------------
def update_html_graphdata(html_path: str, new_graphdata: Dict) -> bool:
    """
    å°‡æ–°çš„ graphData å¯«å› architecture.html

    é‡å¯«é‚è¼¯ï¼š
    1. ä½¿ç”¨äºŒé€²åˆ¶æ¨¡å¼è®€å¯«ï¼Œé¿å…ç·¨ç¢¼å•é¡Œ
    2. json.dumps å¾Œç›´æ¥è™•ç†å­—ç¯€ï¼Œç¢ºä¿è½‰ç¾©åºåˆ—æ­£ç¢ºä¿ç•™
    3. ä½¿ç”¨ newline='' åƒæ•¸é¿å… Windows æ›è¡Œç¬¦å•é¡Œ
    """
    try:
        # 1. è®€å–åŸå§‹ HTMLï¼ˆä½¿ç”¨ UTF-8ï¼‰
        with open(html_path, 'r', encoding='utf-8', newline='') as f:
            html_content = f.read()

        # 2. ç”Ÿæˆ JSON å­—ç¬¦ä¸²ï¼ˆjson.dumps æœƒæ­£ç¢ºè½‰ç¾© \nï¼‰
        # ensure_ascii=False: ä¿ç•™ä¸­æ–‡å­—ç¬¦
        # indent=4: 4ç©ºæ ¼ç¸®é€²ï¼ˆå¾ŒçºŒæœƒèª¿æ•´ç‚º8ç©ºæ ¼ï¼‰
        json_str = json.dumps(new_graphdata, ensure_ascii=False, indent=4)

        # 3. èª¿æ•´ç¸®æ’ï¼šæ¯è¡Œæ·»åŠ  8 å€‹ç©ºæ ¼ï¼ˆä»¥ç¬¦åˆ HTML ä¸­çš„ç¸®æ’ï¼‰
        lines = json_str.split('\n')
        indented_lines = []
        for line in lines:
            if line.strip():  # éç©ºè¡Œ
                indented_lines.append('        ' + line)
            else:  # ç©ºè¡Œ
                indented_lines.append(line)

        indented_json = '\n'.join(indented_lines)

        # 4. çµ„åˆ JavaScript ä»£ç¢¼
        new_js = f"const graphData = {indented_json};"

        # 5. ä½¿ç”¨æ­£å‰‡æ›¿æ› HTML ä¸­çš„ graphData
        # åŒ¹é…æ¨¡å¼ï¼šconst graphData = {...};
        pattern = r'const graphData\s*=\s*\{[\s\S]*?\n\s*\};'

        if not re.search(pattern, html_content):
            print("[ERROR] Could not find 'const graphData = {...};' pattern in HTML")
            return False

        updated_html = re.sub(pattern, new_js, html_content, count=1)

        # 6. å‚™ä»½åŸå§‹ HTML
        backup_path = html_path + '.backup'
        with open(backup_path, 'w', encoding='utf-8', newline='') as f:
            f.write(html_content)

        # 7. å¯«å› HTMLï¼ˆä½¿ç”¨ newline='' é¿å… Windows æ›è¡Œç¬¦è½‰æ›ï¼‰
        with open(html_path, 'w', encoding='utf-8', newline='') as f:
            f.write(updated_html)

        # 8. ğŸ†• å¾Œè™•ç†ä¿®å¾©ï¼šè®€å›æ–‡ä»¶ä¸¦ä¿®å¾©å­—ç¬¦ä¸²å€¼å…§çš„å¯¦éš›æ›è¡Œç¬¦
        # å•é¡Œï¼šPython æ–‡ä»¶å¯«å…¥æ™‚æœƒå°‡æŸäº›è½‰ç¾©åºåˆ—è½‰æ›ç‚ºå¯¦éš›å­—ç¬¦
        # è§£æ±ºï¼šå¯«å…¥å¾Œç«‹å³è®€å›ä¸¦æ‡‰ç”¨ escape_newlines_in_json ä¿®å¾©
        with open(html_path, 'r', encoding='utf-8', newline='') as f:
            html_after_write = f.read()

        # æ‰¾åˆ° graphData å€åŸŸä¸¦ä¿®å¾©
        match = re.search(r'(const graphData\s*=\s*)(\{[\s\S]*?\n\s*\});', html_after_write)
        if match:
            prefix = match.group(1)
            graphdata_str = match.group(2)

            # æ‡‰ç”¨ä¿®å¾©å‡½æ•¸
            fixed_graphdata = escape_newlines_in_json(graphdata_str)

            # é‡å»º HTML
            fixed_html = html_after_write[:match.start()] + prefix + fixed_graphdata + ';' + html_after_write[match.end():]

            # å†æ¬¡å¯«å›
            with open(html_path, 'w', encoding='utf-8', newline='') as f:
                f.write(fixed_html)

        print(f"[OK] Updated graphData in {os.path.basename(html_path)}")
        print(f"[INFO] Backup saved to {os.path.basename(backup_path)}")
        return True

    except Exception as e:
        print(f"[ERROR] Failed to update HTML: {e}")
        import traceback
        traceback.print_exc()
        return False

# ---------------------
# Main
# ---------------------
def main():
    print("=== update_architecture.py (NLWeb ç‰ˆæœ¬) start ===")

    # è¼‰å…¥ YAML
    yaml_data = load_yaml(YAML_PATH) or {"levels": {}}

    # ğŸ†• æª¢æŸ¥æ˜¯å¦æœ‰ architecture-diagram.jsonï¼Œå¦‚æœæœ‰å‰‡å„ªå…ˆä½¿ç”¨
    if os.path.exists(LAYOUT_JSON):
        try:
            with open(LAYOUT_JSON, 'r', encoding='utf-8') as f:
                layout_data = json.load(f)

            if layout_data and 'nodes' in layout_data and len(layout_data['nodes']) > 0:
                print(f"[INFO] Found {LAYOUT_JSON} with {len(layout_data['nodes'])} nodes")
                print("[INFO] Using JSON as source of truth (skipping HTML parsing)")

                # ç›´æ¥å¾ JSON æ§‹å»º parsed_nodes
                parsed_nodes = []
                parsed_groups_dict = {}

                for node in layout_data['nodes']:
                    node_data = {
                        "node_id": node.get('id'),
                        "labelEn": node.get('labelEn', ''),
                        "labelZh": node.get('labelZh', ''),
                        "moduleId": node.get('moduleId', 0),
                        "status": node.get('status', 'unknown'),
                        "rationale": node.get('rationale', ''),
                        "script": node.get('script', ''),
                        "isModuleHeader": node.get('isModuleHeader', False)
                    }
                    parsed_nodes.append(node_data)

                    # å»ºç«‹ groups
                    if node_data['isModuleHeader']:
                        mid = node_data['moduleId']
                        parsed_groups_dict[mid] = {
                            "id": node_data["node_id"],
                            "labelEn": node_data['labelEn'],
                            "labelZh": node_data['labelZh'],
                            "level": 0,
                            "children": []
                        }

                # åˆ†é… children åˆ° groups
                for node_data in parsed_nodes:
                    if not node_data['isModuleHeader']:
                        mid = node_data['moduleId']
                        if mid in parsed_groups_dict:
                            parsed_groups_dict[mid]['children'].append(node_data['node_id'])

                parsed_groups = list(parsed_groups_dict.values())
                print(f"[INFO] Loaded {len(parsed_nodes)} nodes and {len(parsed_groups)} groups from JSON")
            else:
                # JSON ç‚ºç©ºï¼Œå¾ HTML è§£æ
                print("[INFO] JSON is empty, parsing from HTML")
                parsed_nodes, parsed_groups = parse_graphdata_from_html(HTML_FILE)
        except Exception as e:
            print(f"[WARNING] Failed to load JSON: {e}")
            print("[INFO] Falling back to HTML parsing")
            parsed_nodes, parsed_groups = parse_graphdata_from_html(HTML_FILE)
    else:
        # æ²’æœ‰ JSONï¼Œå¾ HTML è§£æ
        print("[INFO] No JSON found, parsing from HTML")
        parsed_nodes, parsed_groups = parse_graphdata_from_html(HTML_FILE)

    # åˆ¤æ–· levels
    nodes_with_levels, groups_final = determine_levels_by_group(parsed_nodes, parsed_groups, yaml_data)

    # CLI æ‰¹é‡è³¦å€¼
    unassigned = [n for n in nodes_with_levels if n.get("level") is None]
    assigned_via_cli, skipped = cli_batch_assign_levels(unassigned, yaml_data)

    # åˆä½µçµæœ
    nid_to_node = {n["node_id"]: n for n in nodes_with_levels}
    for a in assigned_via_cli:
        nid_to_node[a["node_id"]] = a
    final_nodes = list(nid_to_node.values())

    # æ›´æ–° YAML
    new_cnt, updated_cnt = update_yaml_entries(yaml_data, final_nodes, groups_final)

    # åµæ¸¬ç§»é™¤çš„æ¢ç›®
    removed = detect_removed_yaml_entries(yaml_data, final_nodes, groups_final)
    if removed:
        for r in removed:
            print(f"[WARNING] YAML contains '{r}' not in HTML. Manual confirmation required.")

    # ç‹€æ…‹åˆ†æ
    print("\n[INFO] Analyzing implementation status...")
    analyze_status(final_nodes)

    # ä¾è³´é—œä¿‚åˆ†æ
    print("[INFO] Detecting edges (data flow analysis)...")
    edges = detect_edges_from_dataflow(final_nodes)

    # çµ„åˆ graphDataï¼ˆå«ä½ˆå±€ä¿ç•™ï¼‰
    print("[INFO] Composing graphData (preserving layout)...")
    graph = compose_graph_data(final_nodes, groups_final, edges)

    # æ›´æ–° HTML
    print("[INFO] Updating architecture.html...")
    html_updated = update_html_graphdata(HTML_FILE, graph)

    # å¯«å…¥ JSON æª”æ¡ˆ
    with open(GRAPH_JSON, "w", encoding="utf-8") as f:
        json.dump(graph, f, ensure_ascii=False, indent=2)

    # å¯«å…¥ YAML
    save_yaml(YAML_PATH, yaml_data)

    # ç¸½çµ
    print("\n" + "="*60)
    print("[SUMMARY]")
    print(f"[OK] {len(final_nodes)} module nodes processed")
    print(f"[OK] {len(groups_final)} groups processed")
    print(f"[OK] {new_cnt} new YAML entries added")
    print(f"[OK] {updated_cnt} YAML entries updated")
    print(f"[OK] {len(edges)} edges detected")

    # ç‹€æ…‹çµ±è¨ˆ
    status_count = {"done": 0, "partial": 0, "notdone": 0, "header": 0, "unknown": 0}
    for n in final_nodes:
        st = n.get("status", "unknown")
        status_count[st] = status_count.get(st, 0) + 1

    print(f"\n[Status Summary]")
    print(f"  Done: {status_count['done']}")
    print(f"  Partial: {status_count['partial']}")
    print(f"  Not Done: {status_count['notdone']}")
    print(f"  Headers: {status_count['header']}")

    if skipped:
        print(f"\n[WARN] {len(skipped)} nodes skipped: {', '.join(skipped)}")
    if removed:
        print(f"[WARN] {len(removed)} YAML entries not in HTML: {', '.join(removed)}")

    print("\n[Output Files]")
    print(f"  {YAML_PATH} - Level configuration")
    print(f"  {GRAPH_JSON} - Graph data for visualization")
    if html_updated:
        print(f"  {HTML_FILE} - Architecture diagram (UPDATED)")
        print(f"  {HTML_FILE}.backup - Original backup")
    print("="*60)
    print("=== Done ===")

    if html_updated:
        print("\n[NEXT STEPS]")
        print("1. Open static/architecture.html in browser to verify")
        print("2. Adjust layout in edit mode if needed")
        print("3. Export to architecture-diagram.json to save layout")
        print("4. Run this script again to preserve layout")

if __name__ == "__main__":
    main()
